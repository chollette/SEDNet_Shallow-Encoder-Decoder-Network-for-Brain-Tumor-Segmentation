{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a253415",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0c26ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import keras\n",
    "import random                        \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Input, layers\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import concatenate\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input,Concatenate, Conv2D,Conv2DTranspose, SeparableConv2D \n",
    "from tensorflow.keras.layers import BatchNormalization,Activation, Subtract, SpatialDropout2D, Flatten, UpSampling2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd98340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:\\My Documents\\projects\\mri\\BraTS2020_TrainingData - withzero\\MICCAI_BraTS2020_TrainingData - Copy - Copy'\n",
    "os.chdir(path)\n",
    "\n",
    "drs = glob.glob('*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aaa6ab",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a18fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessor import remove_files\n",
    "from preprocessor import check_fileLen\n",
    "from preprocessor import keep_fewSamples\n",
    "\n",
    "# Remove all empty and non-tumor slices in the list\n",
    "files_to_remove1 = remove_files(drs)\n",
    "for file_path in files_to_remove:\n",
    "    os.remove(file_path)\n",
    "\n",
    "# Retrieve the length of the least length of folder \n",
    "perFoldLen = check_fileLen(drs)\n",
    "print(np.min(perFoldLen))\n",
    "\n",
    "# Retain only min slices of all folders\n",
    "files_to_remove2 = keep_fewSamples(drs)\n",
    "for file_path in files_to_remove2:\n",
    "    os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c66d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the remaining slices per sample\n",
    "mask_array = []\n",
    "mask_name = []\n",
    "img_data = []\n",
    "\n",
    "file1 = 'mask'\n",
    "file2 = 'flair'\n",
    "for folder in drs:\n",
    "    if 'BraTS20_Training' in folder:\n",
    "        count = 0\n",
    "        for i in os.listdir(path + '/' + folder + '/' + file1):\n",
    "            im_path1 = os.path.join(folder+'/'+file1,i)\n",
    "            im_path2 = os.path.join(folder+'/'+file2,i)\n",
    "            image1 = cv2.imread(im_path1, cv2.COLOR_BGR2RGB)\n",
    "            image2 = cv2.imread(im_path2, cv2.COLOR_BGR2GRAY)\n",
    "            image2 = image2.astype('uint8')\n",
    "            image2 = np.array(image2)\n",
    "            img_data.append(image2)\n",
    "            image1 = image1.astype('uint8')\n",
    "            image1 = np.array(image1)\n",
    "            mask_array.append(image1)\n",
    "            mask_name.append(i)\n",
    "            count+=1\n",
    "label_data = np.array(mask_array)\n",
    "train_data = np.array(img_data)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dc25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def augmentation(X, Y, seed, batch_size):\n",
    "    \n",
    "    data_gen = dict(rotation_range =15,   \n",
    "                             zoom_range=0.2, \n",
    "                             horizontal_flip = True, \n",
    "                             vertical_flip = True) \n",
    "\n",
    "    image_datagen = ImageDataGenerator(**data_gen)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen)\n",
    "    \n",
    "    Y = np.array(Y)\n",
    "    Y = Y.reshape((1,) + Y.shape) #for 3 channel image\n",
    "    X = np.array(X)\n",
    "    X = X.reshape((1,) + X.shape + (1,))\n",
    "\n",
    "    image_datagen.fit(X, augment=True, seed=seed)\n",
    "    mask_datagen.fit(Y, augment=True, seed=seed)\n",
    "\n",
    "    image_gen = image_datagen.flow(X,Y, batch_size=batch_size, seed=seed)\n",
    "    mask_gen = mask_datagen.flow(Y,X, batch_size=batch_size, seed=seed)\n",
    "    k=0\n",
    "    while True:\n",
    "        re_x = image_gen.next()\n",
    "        re_y = mask_gen.next()\n",
    "        k+=1\n",
    "        if k == 5:\n",
    "            break\n",
    "        \n",
    "    return re_x[0], re_y[0]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f832681",
   "metadata": {},
   "source": [
    "### Create a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single channel \n",
    "# creat h5py data - supports large datasets, larger than RAM size\n",
    "# create HDF5 file\n",
    "#with h5py.File('braintumordataset_singch.hdf5', 'w') as hdb:\n",
    "#    images = hdb.create_dataset('X_images', data=train_data, shape=(8487, 128, 128), compression='gzip', chunks=True)\n",
    "#    mask = hdb.create_dataset('Y_mask', data=label_data, shape=(8487, 128, 128, 3), compression='gzip', chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4143da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read HDF5 file\n",
    "hbd = h5py.File('data/BraTS2020_singchan.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c9f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_images = hbd.get('X_images')[:]\n",
    "YY_mask = hbd.get('Y_mask')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XX_images.shape)\n",
    "print(YY_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close file\n",
    "hbd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(XX_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4996a8b",
   "metadata": {},
   "source": [
    "###  Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e1a3b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset\n",
    "# Split the data into training and testing sets\\n\",\n",
    "X_train, X_VT, y_train, y_VT = train_test_split(XX_images, YY_mask, test_size = 0.2, random_state = 0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_VT, y_VT, test_size=0.5, random_state=0)\n",
    "\n",
    "X_train = np.array(X_train).astype('float32')\n",
    "X_train /=255.0\n",
    "X_val = np.array(X_val).astype('float32')\n",
    "X_val/=255.0\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "X_test/=255.0\n",
    "\n",
    "y_train = np.array(y_train).astype('float32')\n",
    "y_train/=255.0\n",
    "y_val = np.array(y_val).astype('float32')\n",
    "y_val/=255.0\n",
    "y_test = np.array(y_test).astype('float32')\n",
    "y_test/=255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7fe03cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6789, 128, 128)\n",
      "(6789, 128, 128, 3)\n",
      "(849, 128, 128)\n",
      "(849, 128, 128, 3)\n",
      "(849, 128, 128)\n",
      "(849, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a53c6",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c864c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras = tf.compat.v1.keras\n",
    "Sequence = keras.utils.Sequence\n",
    "\n",
    "class MRISeq(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        #elf.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        return batch_x, batch_y \n",
    "\n",
    "train_gen = MRISeq(X_train, y_train, batch_size=23)\n",
    "val_gen = MRISeq(X_val, y_val, batch_size=23)\n",
    "test_gen = MRISeq(X_test, y_test, batch_size=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d925eb",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27434d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lent = []\n",
    "count=0\n",
    "for a, b in train_gen:\n",
    "    lent.append(a)   \n",
    "    images = a\n",
    "    count+=1\n",
    "    for i in range(len(images)):\n",
    "        plt.imshow(images[i])\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    break\n",
    "print(images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "070917ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 23, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(lent).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c64550",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27073280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 128, 32  320         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 32  9248        ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 64, 32)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 64)   18496       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 64)   36928       ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 128)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 128)  147584      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 256)  295168      ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 256)  590080      ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 64, 64, 256)  0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 64, 64)   65600       ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64, 64, 128)  0           ['conv2d_3[0][0]',               \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 64, 64, 64)   73792       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 64, 64, 64)   36928       ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 64  0          ['conv2d_10[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 128, 128, 32  8224        ['up_sampling2d_1[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 128, 64  0           ['conv2d_1[0][0]',               \n",
      "                                )                                 'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 128, 128, 32  18464       ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 128, 128, 32  9248        ['conv2d_12[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 128, 128, 3)  99          ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,384,035\n",
      "Trainable params: 1,384,035\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from model import SEDNet\n",
    "\n",
    "IMG_SIZE=128\n",
    "input_size = Input((IMG_SIZE, IMG_SIZE,1))\n",
    "num_classes = 3\n",
    "model = SEDNet(input_size, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc4b365",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce04d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_metrics import dice_NTC\n",
    "from evaluation_metrics import dice_ED\n",
    "from evaluation_metrics import dice_ET\n",
    "from loss_function import bce_softDice_loss2\n",
    "\n",
    "model = r\"C:\\Users\\joani\\Documents\\unet\\4-channels-AUG\\New folder\\SEDNet-singch_0050.h5\"\n",
    "keras_callbacks   = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3,patience=2, min_lr=0.0000000000000001, verbose=1)]\n",
    "\n",
    "SEDNet = keras.models.load_model(model, compile=False)\n",
    "SEDNet.compile(loss=bce_softDice_loss2, optimizer=keras.optimizers.Adam(learning_rate=0.0003), metrics = [dice_coef, dice_NTC, dice_ED, dice_ET])\n",
    " \n",
    "#freeze first layers, until 19th layer\n",
    "for i in range(19,21):\n",
    "    SEDNet.layers[i].trainable = True\n",
    "\n",
    "x = SEDNet.layers[21].output\n",
    "SEDNetX = Model(inputs=SEDNet.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5442c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = SEDNet.evaluate(test_gen, batch_size=100, callbacks= keras_callbacks)\n",
    "print(score)\n",
    "score = SEDNetX.evaluate(test_gen, batch_size=100, callbacks= keras_callbacks)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d15c856",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc34a8",
   "metadata": {},
   "source": [
    "### Hausdorff distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c21350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_metrics import hausdorff_NTC\n",
    "from evaluation_metrics import hausdorff_ED\n",
    "from evaluation_metrics import hausdorff_ET\n",
    "\n",
    "hdNTC = []\n",
    "hdED = []\n",
    "hdET = []\n",
    "IMG_SIZE = 128\n",
    "X = np.empty((1,IMG_SIZE, IMG_SIZE, 1))\n",
    "y = np.empty((1, IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    X[0,:,:,0] = X_val[i]\n",
    "    y[0,:,:,:] = y_val[i]\n",
    "    p = modell.predict(X, verbose=0)\n",
    "    a, b, c = Hausdorff_distance(y[0,:,:,:], p[0,:,:])\n",
    "    hdNTC.append(a)\n",
    "    hdED.append(b)\n",
    "    hdET.append(c)\n",
    "print(np.mean(hdNTC))\n",
    "print(np.mean(hdED))\n",
    "print(np.mean(hdET))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b67f1b",
   "metadata": {},
   "source": [
    "### Visual Evaluation on Brats2020 testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "\n",
    "X = np.empty((1,IMG_SIZE, IMG_SIZE, 1))\n",
    "y = np.empty((1, IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "X[0,:,:,0] = X_test[170]\n",
    "y[0,:,:,:] = y_test[170]\n",
    "y_pred = SEDNetX.predict(X) \n",
    "\n",
    "plt.imshow(y_pred[0,:,:])\n",
    "plt.imshow(y[0,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9b2ad",
   "metadata": {},
   "source": [
    "### Visual Evaluation on Brats2020 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733531fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "case_path = r\"D:\\My Documents\\projects\\mri\\BraTS2020_TrainingData - withzero\\BraTS2020_ValidationData\\MICCAI_BraTS2020_ValidationData\\BraTS20_Validation_040\\flair\\BraTS20_Validation_040_70.jpg\"\n",
    "\n",
    "X = np.empty((1,IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "X[0,:,:,0] = cv2.imread(case_path,  cv2.COLOR_BGR2GRAY)\n",
    "X = np.array(X).astype('float32')\n",
    "X/=255.0\n",
    "\n",
    "y_pred = SEDNetX.predict(X) \n",
    "plt.imshow(y_pred[0,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
